// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!
//
// Protofile syntax: PROTO3

package io.deephaven.proto.backplane.grpc.partitionedtable

/**
  * A message that describes a partitioned table, able to be sent as a plugin object to a client.
  * This object will also come with a ticket to the underlying table that can be used to get the
  * constituent tables by key.
  *
  * @param keyColumnNames
  *   The names of the key columns. The underlying table will contain these columns - a client can
  *   subscribe to these columns to see what keys are present.
  * @param constituentColumnName
  *   The name of the column in the underlying table that contains the table represented by that row.
  * @param uniqueKeys
  *   True if the keys will be unique, so any set of known keys can be queried using GetTable.
  * @param constituentDefinitionSchema
  *   Returns a flight Messsage wrapping a Schema that will describe every table contained in this
  *   PartitionedTable.
  * @param constituentChangesPermitted
  *   True if the underlying table may tick with updates. See PartitionedTable.constituentChangesPermitted()
  *   for more details.
  */
@SerialVersionUID(0L)
final case class PartitionedTableDescriptor(
    keyColumnNames: _root_.scala.Seq[_root_.scala.Predef.String] = _root_.scala.Seq.empty,
    constituentColumnName: _root_.scala.Predef.String = "",
    uniqueKeys: _root_.scala.Boolean = false,
    constituentDefinitionSchema: _root_.com.google.protobuf.ByteString = _root_.com.google.protobuf.ByteString.EMPTY,
    constituentChangesPermitted: _root_.scala.Boolean = false,
    unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
    ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[PartitionedTableDescriptor] {
    @transient
    private var __serializedSizeMemoized: _root_.scala.Int = 0
    private def __computeSerializedSize(): _root_.scala.Int = {
      var __size = 0
      keyColumnNames.foreach { __item =>
        val __value = __item
        __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(1, __value)
      }
      
      {
        val __value = constituentColumnName
        if (!__value.isEmpty) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(4, __value)
        }
      };
      
      {
        val __value = uniqueKeys
        if (__value != false) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeBoolSize(2, __value)
        }
      };
      
      {
        val __value = constituentDefinitionSchema
        if (!__value.isEmpty) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeBytesSize(3, __value)
        }
      };
      
      {
        val __value = constituentChangesPermitted
        if (__value != false) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeBoolSize(5, __value)
        }
      };
      __size += unknownFields.serializedSize
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var __size = __serializedSizeMemoized
      if (__size == 0) {
        __size = __computeSerializedSize() + 1
        __serializedSizeMemoized = __size
      }
      __size - 1
      
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      keyColumnNames.foreach { __v =>
        val __m = __v
        _output__.writeString(1, __m)
      };
      {
        val __v = uniqueKeys
        if (__v != false) {
          _output__.writeBool(2, __v)
        }
      };
      {
        val __v = constituentDefinitionSchema
        if (!__v.isEmpty) {
          _output__.writeBytes(3, __v)
        }
      };
      {
        val __v = constituentColumnName
        if (!__v.isEmpty) {
          _output__.writeString(4, __v)
        }
      };
      {
        val __v = constituentChangesPermitted
        if (__v != false) {
          _output__.writeBool(5, __v)
        }
      };
      unknownFields.writeTo(_output__)
    }
    def clearKeyColumnNames = copy(keyColumnNames = _root_.scala.Seq.empty)
    def addKeyColumnNames(__vs: _root_.scala.Predef.String *): PartitionedTableDescriptor = addAllKeyColumnNames(__vs)
    def addAllKeyColumnNames(__vs: Iterable[_root_.scala.Predef.String]): PartitionedTableDescriptor = copy(keyColumnNames = keyColumnNames ++ __vs)
    def withKeyColumnNames(__v: _root_.scala.Seq[_root_.scala.Predef.String]): PartitionedTableDescriptor = copy(keyColumnNames = __v)
    def withConstituentColumnName(__v: _root_.scala.Predef.String): PartitionedTableDescriptor = copy(constituentColumnName = __v)
    def withUniqueKeys(__v: _root_.scala.Boolean): PartitionedTableDescriptor = copy(uniqueKeys = __v)
    def withConstituentDefinitionSchema(__v: _root_.com.google.protobuf.ByteString): PartitionedTableDescriptor = copy(constituentDefinitionSchema = __v)
    def withConstituentChangesPermitted(__v: _root_.scala.Boolean): PartitionedTableDescriptor = copy(constituentChangesPermitted = __v)
    def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
    def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => keyColumnNames
        case 4 => {
          val __t = constituentColumnName
          if (__t != "") __t else null
        }
        case 2 => {
          val __t = uniqueKeys
          if (__t != false) __t else null
        }
        case 3 => {
          val __t = constituentDefinitionSchema
          if (__t != _root_.com.google.protobuf.ByteString.EMPTY) __t else null
        }
        case 5 => {
          val __t = constituentChangesPermitted
          if (__t != false) __t else null
        }
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PRepeated(keyColumnNames.iterator.map(_root_.scalapb.descriptors.PString(_)).toVector)
        case 4 => _root_.scalapb.descriptors.PString(constituentColumnName)
        case 2 => _root_.scalapb.descriptors.PBoolean(uniqueKeys)
        case 3 => _root_.scalapb.descriptors.PByteString(constituentDefinitionSchema)
        case 5 => _root_.scalapb.descriptors.PBoolean(constituentChangesPermitted)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
    def companion: io.deephaven.proto.backplane.grpc.partitionedtable.PartitionedTableDescriptor.type = io.deephaven.proto.backplane.grpc.partitionedtable.PartitionedTableDescriptor
    // @@protoc_insertion_point(GeneratedMessage[io.deephaven.proto.backplane.grpc.PartitionedTableDescriptor])
}

object PartitionedTableDescriptor extends scalapb.GeneratedMessageCompanion[io.deephaven.proto.backplane.grpc.partitionedtable.PartitionedTableDescriptor] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[io.deephaven.proto.backplane.grpc.partitionedtable.PartitionedTableDescriptor] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): io.deephaven.proto.backplane.grpc.partitionedtable.PartitionedTableDescriptor = {
    val __keyColumnNames: _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Predef.String] = new _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Predef.String]
    var __constituentColumnName: _root_.scala.Predef.String = ""
    var __uniqueKeys: _root_.scala.Boolean = false
    var __constituentDefinitionSchema: _root_.com.google.protobuf.ByteString = _root_.com.google.protobuf.ByteString.EMPTY
    var __constituentChangesPermitted: _root_.scala.Boolean = false
    var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 10 =>
          __keyColumnNames += _input__.readStringRequireUtf8()
        case 34 =>
          __constituentColumnName = _input__.readStringRequireUtf8()
        case 16 =>
          __uniqueKeys = _input__.readBool()
        case 26 =>
          __constituentDefinitionSchema = _input__.readBytes()
        case 40 =>
          __constituentChangesPermitted = _input__.readBool()
        case tag =>
          if (_unknownFields__ == null) {
            _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
          }
          _unknownFields__.parseField(tag, _input__)
      }
    }
    io.deephaven.proto.backplane.grpc.partitionedtable.PartitionedTableDescriptor(
        keyColumnNames = __keyColumnNames.result(),
        constituentColumnName = __constituentColumnName,
        uniqueKeys = __uniqueKeys,
        constituentDefinitionSchema = __constituentDefinitionSchema,
        constituentChangesPermitted = __constituentChangesPermitted,
        unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[io.deephaven.proto.backplane.grpc.partitionedtable.PartitionedTableDescriptor] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      io.deephaven.proto.backplane.grpc.partitionedtable.PartitionedTableDescriptor(
        keyColumnNames = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Seq[_root_.scala.Predef.String]]).getOrElse(_root_.scala.Seq.empty),
        constituentColumnName = __fieldsMap.get(scalaDescriptor.findFieldByNumber(4).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
        uniqueKeys = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Boolean]).getOrElse(false),
        constituentDefinitionSchema = __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).map(_.as[_root_.com.google.protobuf.ByteString]).getOrElse(_root_.com.google.protobuf.ByteString.EMPTY),
        constituentChangesPermitted = __fieldsMap.get(scalaDescriptor.findFieldByNumber(5).get).map(_.as[_root_.scala.Boolean]).getOrElse(false)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = PartitionedtableProto.javaDescriptor.getMessageTypes().get(4)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = PartitionedtableProto.scalaDescriptor.messages(4)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[?] = throw new MatchError(__number)
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[? <: _root_.scalapb.GeneratedMessage]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[?] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = io.deephaven.proto.backplane.grpc.partitionedtable.PartitionedTableDescriptor(
    keyColumnNames = _root_.scala.Seq.empty,
    constituentColumnName = "",
    uniqueKeys = false,
    constituentDefinitionSchema = _root_.com.google.protobuf.ByteString.EMPTY,
    constituentChangesPermitted = false
  )
  implicit class PartitionedTableDescriptorLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, io.deephaven.proto.backplane.grpc.partitionedtable.PartitionedTableDescriptor]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, io.deephaven.proto.backplane.grpc.partitionedtable.PartitionedTableDescriptor](_l) {
    def keyColumnNames: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[_root_.scala.Predef.String]] = field(_.keyColumnNames)((c_, f_) => c_.copy(keyColumnNames = f_))
    def constituentColumnName: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.constituentColumnName)((c_, f_) => c_.copy(constituentColumnName = f_))
    def uniqueKeys: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Boolean] = field(_.uniqueKeys)((c_, f_) => c_.copy(uniqueKeys = f_))
    def constituentDefinitionSchema: _root_.scalapb.lenses.Lens[UpperPB, _root_.com.google.protobuf.ByteString] = field(_.constituentDefinitionSchema)((c_, f_) => c_.copy(constituentDefinitionSchema = f_))
    def constituentChangesPermitted: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Boolean] = field(_.constituentChangesPermitted)((c_, f_) => c_.copy(constituentChangesPermitted = f_))
  }
  final val KEY_COLUMN_NAMES_FIELD_NUMBER = 1
  final val CONSTITUENT_COLUMN_NAME_FIELD_NUMBER = 4
  final val UNIQUE_KEYS_FIELD_NUMBER = 2
  final val CONSTITUENT_DEFINITION_SCHEMA_FIELD_NUMBER = 3
  final val CONSTITUENT_CHANGES_PERMITTED_FIELD_NUMBER = 5
  def of(
    keyColumnNames: _root_.scala.Seq[_root_.scala.Predef.String],
    constituentColumnName: _root_.scala.Predef.String,
    uniqueKeys: _root_.scala.Boolean,
    constituentDefinitionSchema: _root_.com.google.protobuf.ByteString,
    constituentChangesPermitted: _root_.scala.Boolean
  ): _root_.io.deephaven.proto.backplane.grpc.partitionedtable.PartitionedTableDescriptor = _root_.io.deephaven.proto.backplane.grpc.partitionedtable.PartitionedTableDescriptor(
    keyColumnNames,
    constituentColumnName,
    uniqueKeys,
    constituentDefinitionSchema,
    constituentChangesPermitted
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[io.deephaven.proto.backplane.grpc.PartitionedTableDescriptor])
}
